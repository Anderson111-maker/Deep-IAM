{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d77b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tsgm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55a0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Kyoto_Gases data (2020-2100), consider the case of C1-C8 for simplicity.\n",
    "Kyoto_Gases = pd.read_csv('Kyoto Gases.csv')\n",
    "Kyoto_Gases = Kyoto_Gases[Kyoto_Gases['Category'].isin(['C1','C2','C3','C4','C5','C6','C7','C8'])]\n",
    "mapping = {'C1':0,'C2':0,'C3':0,'C4':1,'C5':1,'C6':1,'C7':2,'C8':2}#Aggregate categories into 3 categories, with 0-2 corresponding to C123-C78, respectively\n",
    "Kyoto_Gases['Category'].replace(mapping,inplace=True)\n",
    "Kyoto_Gases.reset_index(drop=True,inplace=True)\n",
    "Kyoto_Gases.drop(columns=['Category_name'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8780c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a dataset of individual variables\n",
    "CarbonSequestration = pd.read_csv('Carbon_Sequestration_CCS_imputed.csv')\n",
    "FinalEnergy_Liquid = pd.read_csv('Final Energy_Liquids.csv')\n",
    "PrimaryEnergy_Gas = pd.read_csv('Primary Energy_Gas.csv')\n",
    "PrimaryEnergy_Oil = pd.read_csv('Primary Energy_Oil.csv')\n",
    "PrimaryEnergy_Coal = pd.read_csv('PrimaryEnergy_Coal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4969f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the intersection of the models and scenarios contained in each variable\n",
    "Model_Scenario = Kyoto_Gases[['Model','Scenario']]\n",
    "Variables = [CarbonSequestration,FinalEnergy_Liquid,PrimaryEnergy_Coal,PrimaryEnergy_Gas,PrimaryEnergy_Oil]\n",
    "for variable in Variables:\n",
    "    Model_Scenario = pd.merge(Model_Scenario,variable[['Model','Scenario']],on=['Model','Scenario'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada23bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Variables)):\n",
    "    Variables[i] = pd.merge(Model_Scenario,Variables[i],on=['Model','Scenario'],how='inner')\n",
    "for i in range(len(Variables)):\n",
    "    Variables[i].drop(columns=['Category_name'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e751878",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kyoto_Gases = pd.merge(Kyoto_Gases,Model_Scenario,on = ['Model','Scenario'],how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40424a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Variables.append(Kyoto_Gases)\n",
    "#Variables [CarbonSequestration,FinalEnergy_Liquid,PrimaryEnergy_Coal,PrimaryEnergy_Gas,PrimaryEnergy_Oil,Kyoto_Gases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa42dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate feature matrices, the values of each variable during 2020-2100. 9 time steps, 6 features\n",
    "#1160 is the amount of data\n",
    "X = np.zeros((1160,9,6))\n",
    "for i in range(len(Variables)):\n",
    "    Variables[i] = Variables[i].iloc[:,3:-1].values\n",
    "for i in range(1160):\n",
    "    for j in range(9):\n",
    "        for k in range(6):\n",
    "            X[i][j][k] = (Variables[k])[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e992ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Kyoto_Gases['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b85054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate datasets by category. But the training process does not distinguish between categories like VAE\n",
    "C123_DataSet = X[Y == 0]\n",
    "C456_DataSet = X[Y == 1]\n",
    "C78_DataSet = X[Y == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c73a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set problem parameters\n",
    "latent_dim = 38\n",
    "output_dim = 3\n",
    "feature_dim = 6\n",
    "seq_len = 9\n",
    "batch_size = 100\n",
    "generator_in_channels = latent_dim + output_dim\n",
    "discriminator_in_channels = feature_dim + output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec0c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data and compress it to (0, 1).\n",
    "scaler = tsgm.utils.TSFeatureWiseScaler((0,1))\n",
    "X_train = scaler.fit_transform(X)\n",
    "Y_train = keras.utils.to_categorical(Y, 3)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be55c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\keras\\src\\backend.py:6646: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\keras\\src\\backend.py:6646: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "architecture = tsgm.models.architectures.zoo[\"cgan_base_c4_l1\"](\n",
    "    seq_len=seq_len, feat_dim=feature_dim,\n",
    "    latent_dim=latent_dim, output_dim=output_dim)\n",
    "discriminator, generator = architecture.discriminator, architecture.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abda10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an optimization strategy\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,#1e-4\n",
    "    decay_steps=200,#200\n",
    "    decay_rate=0.95)#0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d153d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\l1137\\.conda\\envs\\Pytorch12.2\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 7s 303ms/step - g_loss: 0.6833 - d_loss: 0.6815\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6766 - d_loss: 0.6472\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6743 - d_loss: 0.6106\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.5730 - d_loss: 0.6489\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.4066 - d_loss: 0.8428\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 3s 278ms/step - g_loss: 0.7167 - d_loss: 0.7115\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 3s 276ms/step - g_loss: 1.0629 - d_loss: 0.6326\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 1.2135 - d_loss: 0.6178\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 4s 301ms/step - g_loss: 1.1426 - d_loss: 0.6338\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.9334 - d_loss: 0.6815\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.7233 - d_loss: 0.7302\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.6535 - d_loss: 0.7172\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 4s 300ms/step - g_loss: 0.6703 - d_loss: 0.6728\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6963 - d_loss: 0.6403\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7197 - d_loss: 0.6222\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 3s 279ms/step - g_loss: 0.7572 - d_loss: 0.6193\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.8024 - d_loss: 0.6236\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 4s 292ms/step - g_loss: 0.7462 - d_loss: 0.6675\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7312 - d_loss: 0.6943\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.7785 - d_loss: 0.6817\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.8846 - d_loss: 0.6294\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 4s 303ms/step - g_loss: 0.9542 - d_loss: 0.5850\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.9229 - d_loss: 0.5849\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 3s 276ms/step - g_loss: 0.8455 - d_loss: 0.6227\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 3s 278ms/step - g_loss: 0.7744 - d_loss: 0.6780\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 3s 277ms/step - g_loss: 0.9393 - d_loss: 0.6031\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 1.1036 - d_loss: 0.5169\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 1.0475 - d_loss: 0.5167\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.9763 - d_loss: 0.5730\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.9211 - d_loss: 0.5874\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.9555 - d_loss: 0.5575\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.9830 - d_loss: 0.5242\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 1.0838 - d_loss: 0.4753\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 1.0873 - d_loss: 0.4786\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 1.0626 - d_loss: 0.5166\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 4s 300ms/step - g_loss: 1.0862 - d_loss: 0.5466\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 1.1118 - d_loss: 0.5611\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7195 - d_loss: 0.7289\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.7500 - d_loss: 0.6843\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6995 - d_loss: 0.6298\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 4s 298ms/step - g_loss: 0.7277 - d_loss: 0.6348\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7564 - d_loss: 0.6881\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.8143 - d_loss: 0.6807\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.8730 - d_loss: 0.6049\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.8125 - d_loss: 0.6071\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7635 - d_loss: 0.6136\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.8468 - d_loss: 0.6204\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.8430 - d_loss: 0.6138\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.8645 - d_loss: 0.6034\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 4s 303ms/step - g_loss: 0.7756 - d_loss: 0.6106\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.8498 - d_loss: 0.6131\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.8310 - d_loss: 0.6234\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.8321 - d_loss: 0.6284\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 4s 296ms/step - g_loss: 0.7718 - d_loss: 0.6668\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 4s 305ms/step - g_loss: 0.7025 - d_loss: 0.7019\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6939 - d_loss: 0.7244\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6967 - d_loss: 0.7405\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6992 - d_loss: 0.7269\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 4s 301ms/step - g_loss: 0.6476 - d_loss: 0.7360\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 4s 300ms/step - g_loss: 0.6468 - d_loss: 0.7501\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.6508 - d_loss: 0.7439\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6916 - d_loss: 0.7195\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 4s 296ms/step - g_loss: 0.6962 - d_loss: 0.7334\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.6772 - d_loss: 0.7584\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6953 - d_loss: 0.7535\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6587 - d_loss: 0.7476\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6487 - d_loss: 0.7366\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.6408 - d_loss: 0.7207\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 4s 296ms/step - g_loss: 0.6552 - d_loss: 0.7119\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6786 - d_loss: 0.7106\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6876 - d_loss: 0.7126\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7000 - d_loss: 0.7162\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 4s 292ms/step - g_loss: 0.6908 - d_loss: 0.7198\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6650 - d_loss: 0.7256\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6594 - d_loss: 0.7305\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6641 - d_loss: 0.7284\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6744 - d_loss: 0.7156\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6727 - d_loss: 0.7073\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 3s 278ms/step - g_loss: 0.6762 - d_loss: 0.7040\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6718 - d_loss: 0.7086\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6671 - d_loss: 0.7181\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.6825 - d_loss: 0.7231\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.7036 - d_loss: 0.7146\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6998 - d_loss: 0.7055\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6883 - d_loss: 0.7017\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6912 - d_loss: 0.7054\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.6865 - d_loss: 0.7124\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6687 - d_loss: 0.7186\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6783 - d_loss: 0.7121\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6979 - d_loss: 0.7036\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 4s 305ms/step - g_loss: 0.6929 - d_loss: 0.6984\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 4s 289ms/step - g_loss: 0.6811 - d_loss: 0.6982\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.6694 - d_loss: 0.7040\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6625 - d_loss: 0.7099\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.6709 - d_loss: 0.7133\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 4s 294ms/step - g_loss: 0.6816 - d_loss: 0.7117\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6857 - d_loss: 0.7079\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 4s 292ms/step - g_loss: 0.6891 - d_loss: 0.7038\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6881 - d_loss: 0.7003\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 4s 303ms/step - g_loss: 0.6787 - d_loss: 0.6995\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 4s 301ms/step - g_loss: 0.6740 - d_loss: 0.6999\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6840 - d_loss: 0.7013\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6952 - d_loss: 0.7012\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6866 - d_loss: 0.7020\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 4s 298ms/step - g_loss: 0.6732 - d_loss: 0.7023\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 3s 292ms/step - g_loss: 0.6846 - d_loss: 0.7006\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7167 - d_loss: 0.6986\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.7108 - d_loss: 0.6990\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.6866 - d_loss: 0.7010\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.6894 - d_loss: 0.7007\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6932 - d_loss: 0.7017\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7109 - d_loss: 0.6999\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 3s 280ms/step - g_loss: 0.6771 - d_loss: 0.7027\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6417 - d_loss: 0.6972\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 3s 292ms/step - g_loss: 0.6681 - d_loss: 0.6945\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7061 - d_loss: 0.6950\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7029 - d_loss: 0.6980\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6968 - d_loss: 0.7016\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 4s 302ms/step - g_loss: 0.6949 - d_loss: 0.7032\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 4s 291ms/step - g_loss: 0.6987 - d_loss: 0.7022\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.7102 - d_loss: 0.7016\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.7006 - d_loss: 0.6999\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6608 - d_loss: 0.7002\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6649 - d_loss: 0.6961\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 3s 280ms/step - g_loss: 0.7053 - d_loss: 0.6964\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 3s 280ms/step - g_loss: 0.7453 - d_loss: 0.6921\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6841 - d_loss: 0.6992\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.6413 - d_loss: 0.7007\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.6633 - d_loss: 0.7015\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6984 - d_loss: 0.7015\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7021 - d_loss: 0.7012\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7059 - d_loss: 0.6989\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 4s 296ms/step - g_loss: 0.6920 - d_loss: 0.6999\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6762 - d_loss: 0.6978\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6733 - d_loss: 0.6943\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6833 - d_loss: 0.6942\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 4s 304ms/step - g_loss: 0.7067 - d_loss: 0.6951\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.7382 - d_loss: 0.6931\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6969 - d_loss: 0.6977\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6485 - d_loss: 0.6956\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6577 - d_loss: 0.6985\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.7115 - d_loss: 0.6999\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7275 - d_loss: 0.6987\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.7072 - d_loss: 0.6977\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6923 - d_loss: 0.6947\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.6822 - d_loss: 0.6936\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6796 - d_loss: 0.6942\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6903 - d_loss: 0.6943\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6965 - d_loss: 0.6943\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6775 - d_loss: 0.6965\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 4s 302ms/step - g_loss: 0.6649 - d_loss: 0.6975\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.6935 - d_loss: 0.6998\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.7225 - d_loss: 0.6990\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7023 - d_loss: 0.6980\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 4s 302ms/step - g_loss: 0.6780 - d_loss: 0.6976\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6962 - d_loss: 0.6994\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.7306 - d_loss: 0.6892\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 4s 291ms/step - g_loss: 0.6664 - d_loss: 0.6931\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6499 - d_loss: 0.6927\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 302ms/step - g_loss: 0.6923 - d_loss: 0.6956\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.7266 - d_loss: 0.6980\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 4s 291ms/step - g_loss: 0.7173 - d_loss: 0.6994\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6951 - d_loss: 0.7022\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.6929 - d_loss: 0.7006\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 4s 290ms/step - g_loss: 0.6976 - d_loss: 0.6958\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6915 - d_loss: 0.6911\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6894 - d_loss: 0.6857\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6943 - d_loss: 0.6879\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 4s 305ms/step - g_loss: 0.7053 - d_loss: 0.6949\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.7103 - d_loss: 0.7004\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6919 - d_loss: 0.7047\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6870 - d_loss: 0.7052\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6844 - d_loss: 0.7019\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 4s 304ms/step - g_loss: 0.6756 - d_loss: 0.6979\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6744 - d_loss: 0.6914\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6852 - d_loss: 0.6892\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7056 - d_loss: 0.6926\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 4s 303ms/step - g_loss: 0.7433 - d_loss: 0.6900\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6979 - d_loss: 0.6988\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6694 - d_loss: 0.7015\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.6878 - d_loss: 0.6964\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 4s 291ms/step - g_loss: 0.6955 - d_loss: 0.7001\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 4s 302ms/step - g_loss: 0.7204 - d_loss: 0.6959\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.7102 - d_loss: 0.6943\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6914 - d_loss: 0.6946\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 3s 280ms/step - g_loss: 0.6875 - d_loss: 0.6970\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 4s 292ms/step - g_loss: 0.6907 - d_loss: 0.6997\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6936 - d_loss: 0.7020\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6925 - d_loss: 0.7004\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6883 - d_loss: 0.6964\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6784 - d_loss: 0.6935\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 4s 300ms/step - g_loss: 0.6687 - d_loss: 0.6921\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.6657 - d_loss: 0.6935\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6863 - d_loss: 0.6945\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.7087 - d_loss: 0.6950\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.7056 - d_loss: 0.6988\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.7078 - d_loss: 0.6985\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7196 - d_loss: 0.6935\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7153 - d_loss: 0.6859\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6900 - d_loss: 0.6867\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 4s 301ms/step - g_loss: 0.6782 - d_loss: 0.6918\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.7082 - d_loss: 0.6950\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.7762 - d_loss: 0.6874\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.7155 - d_loss: 0.6943\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6424 - d_loss: 0.6912\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 4s 292ms/step - g_loss: 0.6277 - d_loss: 0.6937\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6935 - d_loss: 0.7020\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7699 - d_loss: 0.6996\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 3s 280ms/step - g_loss: 0.7392 - d_loss: 0.7019\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 4s 294ms/step - g_loss: 0.6950 - d_loss: 0.7052\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6800 - d_loss: 0.7004\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6725 - d_loss: 0.6913\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6639 - d_loss: 0.6916\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 3s 280ms/step - g_loss: 0.6818 - d_loss: 0.6928\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 4s 298ms/step - g_loss: 0.7053 - d_loss: 0.6951\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6915 - d_loss: 0.6958\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6805 - d_loss: 0.6934\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 3s 279ms/step - g_loss: 0.6929 - d_loss: 0.6896\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.7117 - d_loss: 0.6925\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 4s 301ms/step - g_loss: 0.7405 - d_loss: 0.6938\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.7299 - d_loss: 0.6953\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6956 - d_loss: 0.6960\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6831 - d_loss: 0.6982\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6958 - d_loss: 0.6971\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.7021 - d_loss: 0.6957\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6931 - d_loss: 0.6936\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6828 - d_loss: 0.6930\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 4s 303ms/step - g_loss: 0.6794 - d_loss: 0.6929\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 4s 306ms/step - g_loss: 0.6772 - d_loss: 0.6926\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.6723 - d_loss: 0.6920\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6716 - d_loss: 0.6919\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6865 - d_loss: 0.6922\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 4s 300ms/step - g_loss: 0.7102 - d_loss: 0.6930\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 4s 298ms/step - g_loss: 0.7203 - d_loss: 0.6931\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.7099 - d_loss: 0.6956\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.6962 - d_loss: 0.6958\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6926 - d_loss: 0.6937\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 4s 301ms/step - g_loss: 0.6950 - d_loss: 0.6920\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 4s 294ms/step - g_loss: 0.6928 - d_loss: 0.6935\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7045 - d_loss: 0.6943\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.7041 - d_loss: 0.6946\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.6812 - d_loss: 0.6957\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.6636 - d_loss: 0.6944\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6635 - d_loss: 0.6950\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6834 - d_loss: 0.6950\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.7031 - d_loss: 0.6946\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 4s 302ms/step - g_loss: 0.7058 - d_loss: 0.6952\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 4s 294ms/step - g_loss: 0.7126 - d_loss: 0.6931\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.7234 - d_loss: 0.6926\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 4s 291ms/step - g_loss: 0.7317 - d_loss: 0.6911\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.7258 - d_loss: 0.6886\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 4s 297ms/step - g_loss: 0.7077 - d_loss: 0.6883\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.6884 - d_loss: 0.6906\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6695 - d_loss: 0.6934\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6603 - d_loss: 0.6931\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 4s 300ms/step - g_loss: 0.6656 - d_loss: 0.6921\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6906 - d_loss: 0.6910\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.7177 - d_loss: 0.6882\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7069 - d_loss: 0.6925\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 3s 288ms/step - g_loss: 0.6923 - d_loss: 0.7009\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 4s 294ms/step - g_loss: 0.6897 - d_loss: 0.7118\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.6983 - d_loss: 0.7084\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7159 - d_loss: 0.6936\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6906 - d_loss: 0.6938\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.7138 - d_loss: 0.6975\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 4s 291ms/step - g_loss: 0.7581 - d_loss: 0.6911\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.6866 - d_loss: 0.6996\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6490 - d_loss: 0.6960\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 3s 281ms/step - g_loss: 0.6459 - d_loss: 0.6948\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 4s 298ms/step - g_loss: 0.6678 - d_loss: 0.6989\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7191 - d_loss: 0.6940\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7491 - d_loss: 0.6877\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 3s 282ms/step - g_loss: 0.7100 - d_loss: 0.6931\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.6658 - d_loss: 0.6951\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 4s 291ms/step - g_loss: 0.6583 - d_loss: 0.6947\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 3s 285ms/step - g_loss: 0.6812 - d_loss: 0.6947\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7189 - d_loss: 0.6900\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 3s 283ms/step - g_loss: 0.7368 - d_loss: 0.6853\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.7200 - d_loss: 0.6925\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.7434 - d_loss: 0.6946\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 3s 286ms/step - g_loss: 0.7470 - d_loss: 0.6954\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.6783 - d_loss: 0.7003\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6426 - d_loss: 0.6900\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 4s 300ms/step - g_loss: 0.6339 - d_loss: 0.6934\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.6595 - d_loss: 0.7041\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 3s 291ms/step - g_loss: 0.7264 - d_loss: 0.7009\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 3s 287ms/step - g_loss: 0.7798 - d_loss: 0.6886\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 4s 298ms/step - g_loss: 0.7616 - d_loss: 0.6888\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.7064 - d_loss: 0.6983\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 4s 293ms/step - g_loss: 0.6641 - d_loss: 0.7001\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.6489 - d_loss: 0.6954\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 3s 284ms/step - g_loss: 0.6507 - d_loss: 0.6900\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 4s 307ms/step - g_loss: 0.6626 - d_loss: 0.6896\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 4s 301ms/step - g_loss: 0.6801 - d_loss: 0.6919\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.6935 - d_loss: 0.6965\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 3s 289ms/step - g_loss: 0.7040 - d_loss: 0.6992\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 4s 295ms/step - g_loss: 0.7150 - d_loss: 0.7005\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.7214 - d_loss: 0.6988\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 4s 299ms/step - g_loss: 0.7235 - d_loss: 0.6939\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 3s 290ms/step - g_loss: 0.7207 - d_loss: 0.6894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x238c33ef650>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan = tsgm.models.cgan.ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(lr_schedule),\n",
    "    g_optimizer=keras.optimizers.Adam(lr_schedule),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "cond_gan.fit(dataset, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30c131ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set Global Random Seed\n",
    "np.random.seed(8)\n",
    "Gen_Labels = np.zeros(1500)\n",
    "Gen_Labels[500:1000] = 1\n",
    "Gen_Labels[1000:] = 2\n",
    "Gen_Labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dd18cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data using generative models (500 for each class)\n",
    "#Subsequent random forest models partially refer to \"CGAN Random forest.ipynb\"\n",
    "z = np.concatenate([np.random.randn(1500,38),keras.utils.to_categorical(Gen_Labels,3)],axis=1)\n",
    "Gen_Data = generator(z)\n",
    "Gen_Data = Gen_Data.numpy()\n",
    "Gen_Data = scaler.inverse_transform(Gen_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5bdcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15d58f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the cumulative value of the five input variables as a feature of the real dataset\n",
    "features_names = ['CarbonSequestration','FinalEnergy_Liquid','PrimaryEnergy_Coal','PrimaryEnergy_Gas','PrimaryEnergy_Oil']\n",
    "Real_Data_Sum = np.zeros((1160,5))\n",
    "for i in range(1160):#1160 :amount of data\n",
    "    for j in range(5):#5 ：feature dimension\n",
    "        for k in range(8):#time step\n",
    "            Real_Data_Sum[i][j] += (X[i,k,j] + X[i,k+1,j]) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "947f7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_DataSet = pd.DataFrame(Real_Data_Sum,columns=features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "791251d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the feature matrix of the feature cumulative values of the generated dataset\n",
    "Gen_Data_Sum = np.zeros((1500,5))\n",
    "for i in range(1500):#1500 :amount of data\n",
    "    for j in range(5):#5 ：feature dimension\n",
    "        for k in range(8):#time step\n",
    "            Gen_Data_Sum[i][j] += (Gen_Data[i,k,j] + Gen_Data[i,k+1,j]) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf164cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen_DataSet = pd.DataFrame(Gen_Data_Sum,columns=features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a0ae1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First train the model with real datasets to predict the generated data.Cross-validation using grid search\n",
    "R_G = RandomForestClassifier(random_state=42)\n",
    "parameters_1 = {\n",
    "    'n_estimators':[10,100,200,500,1000],\n",
    "    'max_depth':[6,8,10,12,14,16],\n",
    "    'min_samples_split':[3,4,5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41ac7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RG = GridSearchCV(R_G,parameters_1,cv=3,n_jobs=-1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc20b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [6, 8, 10, 12, 14, 16],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100, 200, 500, 1000]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [6, 8, 10, 12, 14, 16],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100, 200, 500, 1000]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 10, 12, 14, 16],\n",
       "                         'min_samples_split': [3, 4, 5, 6],\n",
       "                         'n_estimators': [10, 100, 200, 500, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RG.fit(Real_DataSet,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb8ec3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found:')\n",
    "print(clf_RG.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1af19c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上的测试结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        C123       0.96      0.97      0.97       524\n",
      "        C456       0.96      0.95      0.96       464\n",
      "         C78       1.00      0.98      0.99       172\n",
      "\n",
      "    accuracy                           0.97      1160\n",
      "   macro avg       0.97      0.97      0.97      1160\n",
      "weighted avg       0.97      0.97      0.97      1160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_RG.predict(Real_DataSet)\n",
    "print(f\"在训练集上的测试结果：\")\n",
    "print(classification_report(Y,y_pred,target_names=['C123','C456','C78']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c0c673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在测试集上的测试结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        C123       0.97      1.00      0.98       500\n",
      "        C456       1.00      0.96      0.98       500\n",
      "         C78       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_RG.predict(Gen_DataSet)\n",
    "print(f\"在测试集上的测试结果：\")\n",
    "print(classification_report(Gen_Labels,y_pred,target_names=['C123','C456','C78']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64599a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the generated dataset to train models to predict real data\n",
    "G_R = RandomForestClassifier(random_state=42)\n",
    "parameters_2 = {\n",
    "    'n_estimators':[10,100,200,500,1000],\n",
    "    'max_depth':[6,8,10,12,14,16],\n",
    "    'min_samples_split':[3,4,5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "371fc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GR = GridSearchCV(G_R,parameters_2,cv=3,n_jobs=-1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c178bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [6, 8, 10, 12, 14, 16],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100, 200, 500, 1000]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [6, 8, 10, 12, 14, 16],\n",
       "                         &#x27;min_samples_split&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [10, 100, 200, 500, 1000]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 10, 12, 14, 16],\n",
       "                         'min_samples_split': [3, 4, 5, 6],\n",
       "                         'n_estimators': [10, 100, 200, 500, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GR.fit(Gen_DataSet,Gen_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e7247a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'max_depth': 6, 'min_samples_split': 3, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found:')\n",
    "print(clf_GR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26a2a4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上的测试结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        C123       1.00      1.00      1.00       500\n",
      "        C456       1.00      1.00      1.00       500\n",
      "         C78       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_GR.predict(Gen_DataSet)\n",
    "print(f\"在训练集上的测试结果：\")\n",
    "print(classification_report(Gen_Labels,y_pred,target_names=['C123','C456','C78']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd08332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上的测试结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        C123       0.78      0.85      0.81       524\n",
      "        C456       0.71      0.71      0.71       464\n",
      "         C78       0.88      0.65      0.75       172\n",
      "\n",
      "    accuracy                           0.76      1160\n",
      "   macro avg       0.79      0.73      0.75      1160\n",
      "weighted avg       0.76      0.76      0.76      1160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_GR.predict(Real_DataSet)\n",
    "print(f\"在测试集上的测试结果：\")\n",
    "print(classification_report(Y,y_pred,target_names=['C123','C456','C78']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a90fe868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.save_weights('CGAN_generator.h5')\n",
    "#discriminator.save_weights('CGAN_discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83b7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779297d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e6b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b67cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
